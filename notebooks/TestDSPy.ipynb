{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c7f6b-108c-450e-be93-51ec84c0d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744074b-2194-41ba-bcb4-afe23b8dc3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from curate_gpt.pipeline.pipelines import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c52027-dd0d-4b02-a4e9-d3693cf2acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"USE_AZURE\"] = \"true\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"ff1691b0cd664c4f81ca22128826dfa4\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"ff1691b0cd664c4f81ca22128826dfa4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0255ae1-81e4-4909-bd5b-e971f33c459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Chat with data in a collection.\n",
    "\n",
    "# Example:\n",
    "\n",
    "#     curategpt extract-dspy -c hpoa \"What is the HPO ID for breast cancer?\"\n",
    "# \"\"\"\n",
    "# query = \"What is the HPO ID for breast cancer?\"\n",
    "# result = rag_dspy(query, \"stagedb\", \"hpoa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e50077-3020-4583-9e02-e71a624fd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gt_dataset = pd.read_csv('data/v1_ground_truth_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41af465-5495-4175-a137-2b1e193663ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import BootstrapFewShot, BootstrapFewShotWithRandomSearch, BootstrapFinetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc794d4-51c5-4935-8acb-56c63aff2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import json \n",
    "import dspy\n",
    "\n",
    "def parse_hpo_for_rq(row: pd.Series, col: str) -> list[str]:\n",
    "    return json.loads(row[col])\n",
    "\n",
    "def get_examples(df, limit, inputs):\n",
    "    examples = []\n",
    "    df = df.head(limit)\n",
    "    for _, row in df.iterrows():\n",
    "        rq = row[\"RQ\"]\n",
    "        indication_text = row[\"INDICATION\"]\n",
    "        # question = f'What are the HPO ids for phenotypes in this text? Text: {row[\"INDICATION\"]}'\n",
    "        hpo_ids = parse_hpo_for_rq(row, \"QCED_HPO_IDS\")\n",
    "        hpo_terms = parse_hpo_for_rq(row, \"QCED_HPOS\")\n",
    "        #hpo_ids = \" ,\".join(hpo_ids)  # TODO: Add teleprompter support for list, otherwise we later see AttributeError: 'list' object has no attribute 'split' from the TemplateV2 format handler\n",
    "        example = dict(context=indication_text, hpo_ids=hpo_ids, hpo_terms=hpo_terms)\n",
    "        # example['labels'] = dspy.Example(hpo_ids=hpo_ids)\n",
    "        examples.append(dspy.Example(**example).with_inputs(*inputs))\n",
    "    return examples\n",
    "\n",
    "\n",
    "seed = 10230495\n",
    "train, dev = train_test_split(gt_dataset, test_size=0.3, random_state=seed)\n",
    "\n",
    "train_examples = get_examples(train, 100, ['context', 'labels'])\n",
    "dev_examples = get_examples(dev, 50, ['context', 'labels'])\n",
    "\n",
    "# dataset aliases:\n",
    "train = train_examples\n",
    "trainset = train_examples\n",
    "dev = dev_examples\n",
    "devset = dev_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f346781-2388-45f9-8548-b038392c0fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "language_model = GPT(temperature=0.7, use_azure=True)\n",
    "\n",
    "dspy.settings.configure(lm=language_model)\n",
    "\n",
    "# Define the predictor.\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "\n",
    "# Call the predictor on a particular input.\n",
    "ex0 = train_examples[0].context\n",
    "print(f\"Question: {ex0}\")\n",
    "result = generate_answer(question=f\"Predict HPO IDs for the following text: {ex0}\")\n",
    "\n",
    "language_model.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a1981-00a8-4d45-a07c-f055d0cf5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples[0].labels().hpo_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b5ee6-086f-4268-98c2-cfec2ca124f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "metric_EM = dspy.evaluate.answer_exact_match\n",
    "\n",
    "def normalize(hpo_id: str) -> str:\n",
    "    return hpo_id.strip()\n",
    "\n",
    "\n",
    "# NOTE: sorted may be a bad call\n",
    "def normalize_list(hpo_ids: list[str]) -> list[str]:\n",
    "    return list(filter(None, [normalize(r) for r in hpo_ids]))\n",
    "\n",
    "\n",
    "def metric_recall(gold: list[str], pred: Union[list[str], str], K:int=10) -> float:\n",
    "    \"\"\" Given a gold and predicted list of reactions, normalize and compute recall.\"\"\"\n",
    "    if isinstance(pred, str):\n",
    "        pred = pred.split(\",\")\n",
    "\n",
    "    gold = normalize_list(gold)\n",
    "    pred = normalize_list(pred)[:K]\n",
    "    \n",
    "    gold, pred = set(gold), set(pred)\n",
    "    \n",
    "    intersection = gold.intersection(pred)\n",
    "\n",
    "    recall = len(intersection) / len(gold)\n",
    "    return recall\n",
    "\n",
    "def metric_recallK(gold: list[str], pred: Union[list[str], str], K:int=10) -> float:\n",
    "    return metric_recall(gold, pred, K=K)\n",
    "\n",
    "# wrap the recall@K metric so it can take dspy Examples\n",
    "def dspy_metric_recall10(gold: dspy.Example, pred: dspy.Example, trace=None) -> float:\n",
    "    return metric_recallK(gold.labels().hpo_ids, pred.hpo_ids, K=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5486c-d5ca-4aa4-9704-ef9d6a86427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictHPOs(dspy.Signature):\n",
    "    __doc__ = f\"\"\"Given a snippet from a patient's medical history, identify the Human Phenotype Ontology (HPO) identifier for each phenotype in the text. If none are mentioned in the snippet, say '\\n'.\"\"\"\n",
    "\n",
    "    context = dspy.InputField()\n",
    "    hpo_ids = dspy.OutputField(desc=\"list of comma-separated HPO IDs\", format=lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "\n",
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # here we declare the chain of thought sub-module, so we can later compile it (e.g., teach it a prompt)\n",
    "        self.generate_answer = dspy.ChainOfThought(PredictHPOs)\n",
    "    \n",
    "    def forward(self, context, labels=None):\n",
    "        return self.generate_answer(context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0d434-6d65-44e7-9529-bc1e9242a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_limit = 10\n",
    "threads = 10\n",
    "sample_devset = dev_examples[:example_limit]\n",
    "evaluate_hpo = Evaluate(devset=sample_devset, metric=dspy_metric_recall10, num_threads=threads, display_progress=True, display_table=15)\n",
    "result = evaluate_hpo(CoT())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8edb76-08c6-4266-b7e4-6516fada67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so recall@10 is around 20% uncompiled running eval on 10 threads\n",
    "# weird, result was 36% when stepping through each example with pdb single-threaded.\n",
    "# does pausing give the model more time, and improve answers?\n",
    "print(36.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5577f0-4a10-4fe1-aeb5-22e07d24fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "teleprompter = BootstrapFewShot(metric=dspy_metric_recall10, max_bootstrapped_demos=2)\n",
    "cot_compiled = teleprompter.compile(CoT(), trainset=train_examples[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92325141-fbce-40e6-8c21-e1f577ae17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_compiled(train_examples[0].context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bbe5ff-28c1-4df7-bf37-0901aee5ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_THREADS = 32\n",
    "evaluate_hpo = Evaluate(devset=dev_examples[:10], metric=dspy_metric_recall10, num_threads=NUM_THREADS, display_progress=True, display_table=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796f382-0265-420e-ae03-c2fc8627f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate_hpo(cot_compiled)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f9009-5aa7-42a1-8869-b4fbbc1f5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huge increase (20% -> 40-50% recall) just by compiling the model over 10 examples. let's inspect the prompt:\n",
    "language_model.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56919402-b01b-443a-a8d8-965ab3cf7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(cot_compiled)\n",
    "cot_compiled.save(\"data/cot_compiled_50pct_recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2addcab-70d0-436e-b867-882977b299f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from curate_gpt.pipeline import retrieval\n",
    "importlib.reload(retrieval)\n",
    "\n",
    "retrieve_model = retrieval.ChromadbForAzureRM.from_dir(\n",
    "    persist_directory=\"stagedb\",\n",
    "    collection_name=\"hpoa\",\n",
    "    use_azure=True\n",
    ")\n",
    "dspy.settings.configure(rm=retrieve_model, lm=language_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f36bfec-dae7-430c-8a89-af9aaee216cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchQueryForHPOs(dspy.Signature):\n",
    "    __doc__ = f\"\"\"Given a snippet from a patient's medical history, create a search query for the Human Phenotype Ontology (HPO) identifier for each phenotype in the text.\"\"\"\n",
    "\n",
    "    context = dspy.InputField()\n",
    "    search_query = dspy.OutputField(desc=\"search query to retrieve HPO document texts\")\n",
    "\n",
    "\n",
    "class PredictWithSearchHPOs(dspy.Signature):\n",
    "    __doc__ = f\"\"\"Given a snippet from a patient's medical history and the search results, identify the Human Phenotype Ontology (HPO) identifier for each phenotype in the text. If none are mentioned in the snippet, say '\\n'.\"\"\"\n",
    "\n",
    "    context = dspy.InputField()\n",
    "    documents = dspy.InputField(desc=\"HPO document texts\", format=lambda x: '\\n\\n'.join(x) if isinstance(x, list) else x)\n",
    "    hpo_ids = dspy.OutputField(desc=\"list of comma-separated HPO IDs\", format=lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # declare three modules: the retriever, a query generator, and an answer generator\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_query = dspy.ChainOfThought(SearchQueryForHPOs)\n",
    "        self.generate_answer = dspy.ChainOfThought(PredictWithSearchHPOs)\n",
    "    \n",
    "    def forward(self, context, labels=None):\n",
    "        # generate a search query from the context, and use it to retrieve passages\n",
    "        search_query = self.generate_query(context=context).search_query\n",
    "        documents = self.retrieve(search_query).passages\n",
    "\n",
    "        # generate an answer from the passages and the question\n",
    "        return self.generate_answer(context=context, documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd004f45-f284-4c76-986b-1a9929db5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_hpo(RAG(), display_table=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f4c93-d69b-4762-9caa-159c86bf4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty good! >28% uncompiled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06afacb-7bb4-4db0-bf01-65774d510b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = train_examples[2].context\n",
    "retrieve = dspy.Retrieve(k=3)\n",
    "top_passages = retrieve(query).passages\n",
    "print(f\"Query: {query}\")\n",
    "for passage in top_passages:\n",
    "    print(\"=\" * 30)\n",
    "    print(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced51b0-6cf7-449b-adf5-e33d6ee610d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 10\n",
    "teleprompter2 = BootstrapFewShotWithRandomSearch(metric=dspy_metric_recall10, max_bootstrapped_demos=2, num_candidate_programs=2, num_threads=threads)\n",
    "rag_compiled = teleprompter2.compile(RAG(), trainset=train_examples[:20], valset=dev_examples[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3f302-7a25-4166-ba1d-2c5ca9d8e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 10\n",
    "ex = dev_examples[40:50]\n",
    "print(len(dev_examples))\n",
    "evaluate_hpo = Evaluate(devset=ex, metric=dspy_metric_recall10, num_threads=threads, display_progress=True, display_table=15)\n",
    "result = evaluate_hpo(rag_compiled)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9f0ee-3dac-4778-8e7d-82242426231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model.inspect_history(n=2, skip=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5115a9-70c8-431c-b7bd-71336b43b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79831302-0ff1-48c2-a908-c5357f204cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avm_example = dev_examples[45]\n",
    "pred = rag_compiled(avm_example.context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9995576-6026-4ecd-be21-d5b0539a8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47978559-f7ba-4aca-97b0-0e8e0dcb5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.hpo_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd89c8-db8b-42c5-a4c9-40a6b4d7eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avm_result = dspy_metric_recall10(avm_example, pred)\n",
    "avm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98870d2a-5eb3-492c-a29c-fc64aa75c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = train_examples[2].context\n",
    "\n",
    "answer = rag_compiled(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdb351-de55-429f-8b1c-562d39770121",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model.inspect_history(n=1, skip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf66416-92ac-443b-9b12-e2e3d107d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples[2].labels().hpo_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b0a29-f8d5-4d90-abde-d94e957ef8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One problem with the current approach is that we're only retrieving results for one of the phenotypes it seems, e.g. Goiter in the above example.\n",
    "# One option is to use MultiHop\n",
    "# Another is to use something like PredictThenGround\n",
    "# https://colab.research.google.com/drive/1CpsOiLiLYKeGrhmq579_FmtGsD5uZ3Qe#scrollTo=0TjOZmXEUDie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e055c-d0a0-4c7a-98ee-d408d63b4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dsp.utils.utils import deduplicate\n",
    "\n",
    "# class MultiHop(dspy.Module):\n",
    "#     def __init__(self, num_passages=10):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "#         self.generate_query = dspy.ChainOfThought(\"question -> search_query\")\n",
    "\n",
    "#         self.generate_query_from_context = dspy.ChainOfThought(\"context, question -> search_query\")\n",
    "\n",
    "#         self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "    \n",
    "#     def forward(self, question):\n",
    "#         passages = []\n",
    "        \n",
    "#         search_query = self.generate_query(question=question).search_query\n",
    "#         passages += self.retrieve(search_query).passages\n",
    "\n",
    "#         search_query2 = self.generate_query_from_context(context=deduplicate(passages), question=question).search_query\n",
    "\n",
    "#         passages += self.retrieve(search_query2).passages\n",
    "\n",
    "#         return self.generate_answer(context=deduplicate(passages), question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c52a5-531e-4a60-abfd-8c5aafeb9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threads = 32\n",
    "# teleprompter3 = BootstrapFewShotWithRandomSearch(metric=metric_EM, max_bootstrapped_demos=2, num_candidate_programs=2, num_threads=threads)\n",
    "# multihop_compiled = teleprompter3.compile(MultiHop(), trainset=train_examples, valset=dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c7ff4-5b56-4afc-9069-3efb21f4dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_hpo(multihop_compiled, devset=dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84fded-e66f-4eb1-b7c0-67a9434f9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = train_examples[3].question\n",
    "\n",
    "# multihop_compiled(question=query)\n",
    "\n",
    "# language_model.inspect_history(n=1, skip=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49224761-86c7-403d-a671-a8f6f65937ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language_model.inspect_history(n=1, skip=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022a910-4ffc-46e7-92b5-2d926667a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_examples[3].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe33bb-a0c8-4b19-af34-fc1da99d7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97d9c6-3269-408c-93b9-de0d2675097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "# Work on multihop to only query text from original passage.... the question was changed.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efb6816-d102-4a5c-b356-0edd3e2a49ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
