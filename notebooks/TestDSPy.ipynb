{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c7f6b-108c-450e-be93-51ec84c0d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744074b-2194-41ba-bcb4-afe23b8dc3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from curate_gpt.pipeline.pipelines import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c52027-dd0d-4b02-a4e9-d3693cf2acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"USE_AZURE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0255ae1-81e4-4909-bd5b-e971f33c459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Chat with data in a collection.\n",
    "\n",
    "Example:\n",
    "\n",
    "    curategpt extract-dspy -c hpoa \"What is the HPO ID for breast cancer?\"\n",
    "\"\"\"\n",
    "query = \"What is the HPO ID for breast cancer?\"\n",
    "result = rag_dspy(query, \"stagedb\", \"hpoa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb1672-7de8-434d-8d50-7e9b206b492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# # Validation logic: check that the predicted answer is correct.\n",
    "# # Also check that the retrieved context does actually contain that answer.\n",
    "# def validate_context_and_answer(example, pred, trace=None):\n",
    "#     answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "#     answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "#     return answer_EM and answer_PM\n",
    "\n",
    "# # Set up a basic teleprompter, which will compile our RAG program.\n",
    "# teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "\n",
    "# # Compile!\n",
    "# compiled_rag = teleprompter.compile(RAG(), trainset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e50077-3020-4583-9e02-e71a624fd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gt_dataset = pd.read_csv('data/v1_ground_truth_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41af465-5495-4175-a137-2b1e193663ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import BootstrapFewShot, BootstrapFewShotWithRandomSearch, BootstrapFinetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc794d4-51c5-4935-8acb-56c63aff2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import json \n",
    "\n",
    "\n",
    "def parse_hpo_for_rq(row: pd.Series, col: str) -> list[str]:\n",
    "    return json.loads(row[col])\n",
    "\n",
    "def get_examples(df, limit):\n",
    "    examples = []\n",
    "    df = df.head(limit)\n",
    "    for _, row in df.iterrows():\n",
    "        rq = row[\"RQ\"]\n",
    "        question = f'What are the HPO ids for phenotypes in this text? Text: {row[\"INDICATION\"]}'\n",
    "        hpo_ids = parse_hpo_for_rq(row, \"QCED_HPO_IDS\")\n",
    "        hpo_ids = \" ,\".join(hpo_ids)  # TODO: Add teleprompter support for list, otherwise we later see AttributeError: 'list' object has no attribute 'split' from the TemplateV2 format handler\n",
    "        ex = dspy.Example(question=question, answer=hpo_ids).with_inputs('question') \n",
    "        examples.append(ex)\n",
    "    return examples\n",
    "\n",
    "\n",
    "seed = 10230495\n",
    "train, dev = train_test_split(gt_dataset, test_size=0.2, random_state=seed)\n",
    "\n",
    "train_examples = get_examples(train, 10)\n",
    "dev_examples = get_examples(dev, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f346781-2388-45f9-8548-b038392c0fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "language_model = GPT(temperature=0.7)\n",
    "\n",
    "dspy.settings.configure(lm=language_model)\n",
    "\n",
    "# Define the predictor.\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "\n",
    "# Call the predictor on a particular input.\n",
    "print(f\"Question: {train_examples[0].question}\")\n",
    "result = generate_answer(question=train_examples[0].question)\n",
    "\n",
    "language_model.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a1981-00a8-4d45-a07c-f055d0cf5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples[0].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b5ee6-086f-4268-98c2-cfec2ca124f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_EM = dspy.evaluate.answer_exact_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5486c-d5ca-4aa4-9704-ef9d6a86427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CoT(dspy.Module):  # let's define a new module\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # here we declare the chain of thought sub-module, so we can later compile it (e.g., teach it a prompt)\n",
    "        self.generate_answer = dspy.ChainOfThought('question -> answer')\n",
    "    \n",
    "    def forward(self, question):\n",
    "        return self.generate_answer(question=question)  # here we use the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0d434-6d65-44e7-9529-bc1e9242a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teleprompter = BootstrapFewShot(metric=metric_EM, max_bootstrapped_demos=2)\n",
    "cot_compiled = teleprompter.compile(CoT(), trainset=train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92325141-fbce-40e6-8c21-e1f577ae17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_compiled(train_examples[0].question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bbe5ff-28c1-4df7-bf37-0901aee5ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_THREADS = 32\n",
    "evaluate_hpo = Evaluate(devset=dev_examples, metric=metric_EM, num_threads=NUM_THREADS, display_progress=True, display_table=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796f382-0265-420e-ae03-c2fc8627f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_hpo(cot_compiled)\n",
    "# dev_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2addcab-70d0-436e-b867-882977b299f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_model = ChromadbForAzureRM.from_dir(\n",
    "    persist_directory=\"stagedb\",\n",
    "    collection_name=\"hpoa\",\n",
    ")\n",
    "dspy.settings.configure(rm=retrieve_model, lm=language_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f36bfec-dae7-430c-8a89-af9aaee216cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # declare three modules: the retriever, a query generator, and an answer generator\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_query = dspy.ChainOfThought(\"question -> search_query\")\n",
    "        self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        # generate a search query from the question, and use it to retrieve passages\n",
    "        search_query = self.generate_query(question=question).search_query\n",
    "        passages = self.retrieve(search_query).passages\n",
    "\n",
    "        # generate an answer from the passages and the question\n",
    "        return self.generate_answer(context=passages, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd004f45-f284-4c76-986b-1a9929db5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_hpo(RAG(), display_table=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06afacb-7bb4-4db0-bf01-65774d510b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = train_examples[2].question\n",
    "retrieve = dspy.Retrieve(k=3)\n",
    "top_passages = retrieve(query).passages\n",
    "print(f\"Query: {query}\")\n",
    "for passage in top_passages:\n",
    "    print(\"=\" * 30)\n",
    "    print(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced51b0-6cf7-449b-adf5-e33d6ee610d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "teleprompter2 = BootstrapFewShotWithRandomSearch(metric=metric_EM, max_bootstrapped_demos=2, num_candidate_programs=8, num_threads=NUM_THREADS)\n",
    "rag_compiled = teleprompter2.compile(RAG(), trainset=train_examples, valset=dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98870d2a-5eb3-492c-a29c-fc64aa75c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = train_examples[2].question\n",
    "\n",
    "answer = rag_compiled(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdb351-de55-429f-8b1c-562d39770121",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e055c-d0a0-4c7a-98ee-d408d63b4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils.utils import deduplicate\n",
    "\n",
    "class MultiHop(dspy.Module):\n",
    "    def __init__(self, num_passages=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_query = dspy.ChainOfThought(\"question -> search_query\")\n",
    "\n",
    "        self.generate_query_from_context = dspy.ChainOfThought(\"context, question -> search_query\")\n",
    "\n",
    "        self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        passages = []\n",
    "        \n",
    "        search_query = self.generate_query(question=question).search_query\n",
    "        passages += self.retrieve(search_query).passages\n",
    "\n",
    "        search_query2 = self.generate_query_from_context(context=deduplicate(passages), question=question).search_query\n",
    "\n",
    "        # TODO: Replace `None` with a call to self.retrieve to retrieve passages. Append them to the list `passages`.\n",
    "        passages += self.retrieve(search_query2).passages\n",
    "\n",
    "        return self.generate_answer(context=deduplicate(passages), question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c52a5-531e-4a60-abfd-8c5aafeb9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "teleprompter3 = BootstrapFewShotWithRandomSearch(metric=metric_EM, max_bootstrapped_demos=2, num_candidate_programs=2, num_threads=NUM_THREADS)\n",
    "\n",
    "multihop_compiled = teleprompter3.compile(MultiHop(), trainset=train_examples, valset=dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c7ff4-5b56-4afc-9069-3efb21f4dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_hpo(multihop_compiled, devset=dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84fded-e66f-4eb1-b7c0-67a9434f9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = train_examples[3].question\n",
    "\n",
    "multihop_compiled(question=query)\n",
    "\n",
    "language_model.inspect_history(n=1, skip=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
